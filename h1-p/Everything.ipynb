{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === Part I ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python count_freqs.py gene.train > gene.counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram Tag Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('gene.ngrams', sep=' ', names=['Count', 'NGram', 'One', 'Two', 'Three'])\n",
    "\n",
    "unigram_count = {}\n",
    "\n",
    "for tag, count in df[df['NGram'] == '1-GRAM'][['One', 'Count']].values:\n",
    "    unigram_count[tag] = count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Token Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('gene.counts', 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "c = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for line in lines:\n",
    "    count, _, tag, token = line.split()\n",
    "    c[token][tag] = int(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rare Word Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric, ALL_CAPITAL, last_capitaL, rare = set(), set(), set(), set()\n",
    "\n",
    "for token in c:\n",
    "    # Rare word?\n",
    "    if c[token]['O'] + c[token]['I-GENE'] < 5:\n",
    "        # Numeric?\n",
    "        try:\n",
    "            int(token)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        else:\n",
    "            numeric.add(token)\n",
    "            continue\n",
    "        \n",
    "        # ALL CAPITAL?\n",
    "        if token.isupper():\n",
    "            ALL_CAPITAL.add(token)\n",
    "            continue\n",
    "        \n",
    "        # last capitaL?\n",
    "        if token[-1].isupper():\n",
    "            last_capitaL.add(token)\n",
    "            continue\n",
    "        \n",
    "        # It's just rare\n",
    "        rare.add(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Rare Word Classes Back To Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('gene.train', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "with open('rare.train', 'w') as f:\n",
    "    for line in lines:\n",
    "        # Empty line?\n",
    "        if not line.strip():\n",
    "            f.write(line)\n",
    "            continue\n",
    "        \n",
    "        token, tag = line.split()\n",
    "        \n",
    "        if token in numeric:\n",
    "            f.write(' '.join(['_NUMERIC_', tag]) + '\\n')\n",
    "        elif token in ALL_CAPITAL:\n",
    "            f.write(' '.join(['_ALL_CAPITAL_', tag]) + '\\n')\n",
    "        elif token in last_capitaL:\n",
    "            f.write(' '.join(['_last_capitaL_', tag]) + '\\n')\n",
    "        elif token in rare:\n",
    "            f.write(' '.join(['_RARE_', tag]) + '\\n')\n",
    "        else:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recompute Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python count_freqs.py rare.train > gene.counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read All Words Back in One More Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('gene.counts', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "for line in lines:\n",
    "    count, _, tag, token = line.split()\n",
    "    c[token][tag] = int(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Emission Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for token in c:\n",
    "    for tag in c[token]:\n",
    "        e[token][tag] = c[token][tag] / float(unigram_count[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<type 'int'>, {'I-GENE': 0.0009495520062329567, 'O': 0.0033060197955541134})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['_NUMERIC_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<type 'int'>, {'I-GENE': 0.07752239968835216, 'O': 0.01066850559792309})"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['_ALL_CAPITAL_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<type 'int'>, {'I-GENE': 0.024858784573432022, 'O': 0.0008228831042395864})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['_last_capitaL_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<type 'int'>, {'I-GENE': 0.10927152317880795, 'O': 0.06859484017523933})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['_RARE_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# === Part II ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('gene.ngrams', sep=' ', names=['Count', 'NGram', 'One', 'Two', 'Three'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "bigram_count = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for count, BIGRAM, tag_one, tag_two, _ in df[df['NGram'] == '2-GRAM'].values.tolist():\n",
    "    bigram_count[tag_one][tag_two] = count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "trigram_count = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "for count, TRIGRAM, tag_one, tag_two, tag_three in df[df['NGram'] == '3-GRAM'].values.tolist():\n",
    "    trigram_count[tag_one][tag_two][tag_three] = count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute $q_\\text{MLE}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "q = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "for next, current, previous in itertools.product(['*', 'STOP', 'O', 'I-GENE'], repeat=3):\n",
    "    # Ignore situations where the premise is impossible\n",
    "    if not bigram_count[previous][current]:\n",
    "        continue\n",
    "        \n",
    "    q[next][previous][current] = trigram_count[previous][current][next] / float(bigram_count[previous][current])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "pi = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "\n",
    "def viterbi(xs, q, e):\n",
    "    # Initialize pi\n",
    "    pi[0]['*']['*'], n = 1, len(xs)\n",
    "    \n",
    "    # Initialize S such that:\n",
    "    #   S(-1) = S(0) = ['*']\n",
    "    #   S(1:n) (inclusive) = ['O', 'I-GENE']\n",
    "    #   S(n+1) = ['STOP']\n",
    "    S = [['*']] + [('O', 'I-GENE') for _ in range(n) ] + [['STOP']] + [['*']]\n",
    "    \n",
    "    for k, x in enumerate(xs.split(), start=1):\n",
    "        for u, v in itertools.product(S[k-1], S[k]):\n",
    "            print 'Calculating pi[{}][{}][{}] = max w in {}...'.format(k, u, v, S[k-2])\n",
    "            \n",
    "            pi[k][u][v] = max([ pi[k-1][w][u]*q[v][w][u]*e[x][v] for w in S[k-2] ])\n",
    "        \n",
    "    return max([ pi[n][u][v]*q['STOP'][u][v] for u, v in itertools.product(S[n-1], S[n]) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating pi[1][*][O] = max w in ['*']...\n",
      "Calculating pi[1][*][I-GENE] = max w in ['*']...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi('the', q, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "highest_prob, backpointer = defaultdict(lambda: defaultdict(lambda: defaultdict(int))), defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "\n",
    "def viterbi(xs, transition, emission):\n",
    "    # Initialize highest_prob\n",
    "    highest_prob[0]['*']['*'], n, = 1, len(xs.split())\n",
    "    y = [''] * (n+1)\n",
    "    \n",
    "    # Initialize possible_tags such that:\n",
    "    #   possible_tags(-1) = possible_tags(0) = ['*']\n",
    "    #   possible_tags(1:n) (inclusive) = ['O', 'I-GENE']\n",
    "    #   possible_tags(n+1) = ['STOP']\n",
    "    possible_tags = [['*']] + [('O', 'I-GENE') for _ in range(n) ] + [['STOP']] + [['*']]\n",
    "    \n",
    "    print 'For k = 1...{}'.format(n)\n",
    "    print\n",
    "    \n",
    "    for k, x in enumerate(xs.split(), start=1):\n",
    "        print '** Time to compute highest_prob(k={}, u, v) for all u in possible_tags({})={} and v in possible_tags({})={}...'.format(k, k-1, possible_tags[k-1], k, possible_tags[k])\n",
    "        print\n",
    "        \n",
    "        for u, v in itertools.product(possible_tags[k-1], possible_tags[k]):\n",
    "            print '    ==========================================================================================================='\n",
    "            print '    Calculating highest_prob(k={}, u={}, v={}) = max over w in possible_tags({})={} of highest_prob({}, w, u={}) * transition(v={} | w, u={}) * emission(x={} | v={})...'.format(k,u,v,k-2,possible_tags[k-2],k-1,u,v,u,x,v)\n",
    "            print\n",
    "            \n",
    "            currents = []\n",
    "            for w in possible_tags[k-2]:\n",
    "                print '    Trying w={}...'.format(w)\n",
    "                print '    Computing highest_prob({}, w={}, u={}) * transition(v={} | w={}, u={}) * emission(x={} | v={}) where:'.format(k-1,w,u,v,w,u,x,v)\n",
    "                print\n",
    "                print '        highest_prob({}, w={}, u={}) = {}'.format(k-1,w,u,highest_prob[k-1][w][u])\n",
    "                print '        transition(v={} | w={}, u={}) = {}'.format(v,w,u,transition[v][w][u])\n",
    "                print '        emission(x={} | v={}) = {}'.format(x,v,emission[x if x not in infrequent_words and emission[x] else '_RARE_'][v])\n",
    "                print\n",
    "                \n",
    "                current = highest_prob[k-1][w][u] * transition[v][w][u] * emission[x if x not in infrequent_words and emission[x] else '_RARE_'][v]\n",
    "                \n",
    "                print '    Result = {}'.format(current)\n",
    "                currents.append((current, w))\n",
    "                print\n",
    "               \n",
    "            print\n",
    "            print '    Highest probability tagging is: {}'.format(max(currents))\n",
    "            print '    ==========================================================================================================='\n",
    "            highest_prob[k][u][v], backpointer[k][u][v] = max(currents)\n",
    "            \n",
    "            print       \n",
    "    \n",
    "    print '** Finally compute max of highest_prob(n={}, u, v) * transition(STOP | u, v) over all u in possible_tags({})={} and v in possible_tags({})={}...'.format(n, n-1, possible_tags[n-1], n, possible_tags[n])\n",
    "    print\n",
    "    \n",
    "    currents = []\n",
    "    for u, v in itertools.product(possible_tags[n-1], possible_tags[n]):\n",
    "        print '    ==========================================================================================================='\n",
    "        print '    Computing highest_prob(n={}, u={}, v={}) * transition(STOP | u={}, v={}) where:'.format(n,u,v,u,v)\n",
    "        print\n",
    "        print '        highest_prob(n={}, u={}, v={}) = {}'.format(n,u,v,highest_prob[n][u][v])\n",
    "        print '        transition(STOP | u={}, v={}) = {}'.format(u,v,transition['STOP'][u][v])\n",
    "        print\n",
    "        \n",
    "        current = highest_prob[n][u][v] * transition['STOP'][u][v]\n",
    "        print '    Result = {}'.format(current)\n",
    "        currents.append((current, u, v))\n",
    "       \n",
    "    print\n",
    "    print '    Highest probability tagging is: {}'.format(max(currents))\n",
    "    print '    ==========================================================================================================='\n",
    "\n",
    "    # Compute Backpoints\n",
    "    _, y[n-1], y[n] = max(currents)\n",
    "    for k in range(n-2, 0, -1):\n",
    "        y[k] = backpointer[k+2][y[k+1]][y[k+2]]\n",
    "        \n",
    "    return y[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean(er) Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "\n",
    "highest_prob, backpointer = defaultdict(lambda: defaultdict(lambda: defaultdict(int))), defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "\n",
    "def viterbi(xs, transition, emission):\n",
    "    # Initialize highest_prob\n",
    "    highest_prob[0]['*']['*'], n, = 1, len(xs.split())\n",
    "    y = [''] * (n+1)\n",
    "    \n",
    "    # Initialize possible_tags such that:\n",
    "    #   possible_tags(-1) = possible_tags(0) = ['*']\n",
    "    #   possible_tags(1:n) (inclusive) = ['O', 'I-GENE']\n",
    "    #   possible_tags(n+1) = ['STOP']\n",
    "    possible_tags = [['*']] + [('O', 'I-GENE') for _ in range(n) ] + [['STOP']] + [['*']]\n",
    "    \n",
    "    for k, x in enumerate(xs.split(), start=1):\n",
    "        for u, v in itertools.product(possible_tags[k-1], possible_tags[k]):\n",
    "            \n",
    "            currents = []\n",
    "            for w in possible_tags[k-2]:\n",
    "                \n",
    "                # Rare word class?\n",
    "                if x in numeric:\n",
    "                    x = '_NUMERIC_'\n",
    "                elif x in ALL_CAPITAL:\n",
    "                    x = '_ALL_CAPITAL_'\n",
    "                elif x in last_capitaL:\n",
    "                    x = '_last_capitaL_'\n",
    "                elif x in rare or not emission[x]:\n",
    "                    x = '_RARE_'\n",
    "                    \n",
    "                current = highest_prob[k-1][w][u] * transition[v][w][u] * emission[x][v]\n",
    "                currents.append((current, w))\n",
    "               \n",
    "            highest_prob[k][u][v], backpointer[k][u][v] = max(currents)\n",
    "    \n",
    "    currents = []\n",
    "    for u, v in itertools.product(possible_tags[n-1], possible_tags[n]):\n",
    "        current = highest_prob[n][u][v] * transition['STOP'][u][v]\n",
    "        currents.append((current, u, v))\n",
    "       \n",
    "    # Compute Backpoints\n",
    "    _, y[n-1], y[n] = max(currents)\n",
    "    for k in range(n-2, 0, -1):\n",
    "        y[k] = backpointer[k+2][y[k+1]][y[k+2]]\n",
    "        \n",
    "    return y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-GENE', 'I-GENE', 'O']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi('gene gene gene', q, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('gene.dev', 'r') as f:\n",
    "    tokens = [''] + [ line.strip() for line in f.readlines() ]\n",
    "    \n",
    "indicies = [ i for i, token in enumerate(tokens) if not token ]\n",
    "sentences = [ ' '.join(tokens[beg+1:end]) for beg, end in zip(indicies, indicies[1:]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = [ (sentence.split(), viterbi(sentence, q, e)) for sentence in sentences ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Predictions Back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('gene.', 'w') as f:\n",
    "    for sentence, tags in predictions:\n",
    "        for token, tag in zip(sentence, tags):\n",
    "            f.write(' '.join([token, tag]) + '\\n')\n",
    "        \n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not align gold standard and predictions in line 1.\n",
      "Gold standard: BACKGROUND  Prediction file: Third\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "run eval_gene_tagger gene.key gene.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
